{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKw1vGIYfNqI",
        "outputId": "20070f80-5dda-419b-d284-f505a6bc24f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.230105-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.7)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=27b74bae757121a38067a60d408c47a9d9b474d9db9271c126111dd9976ca3f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.230105 types-pytz-2022.7.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f tuning_88R_data.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbPF7QsqfqHs",
        "outputId": "f6c97b83-70d7-4a79-f572-e89833dd32da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 281 prompt-completion pairs\n",
            "- There are 10 duplicated prompt-completion sets. These are rows: [47, 64, 165, 213, 226, 259, 266, 269, 277, 279]\n",
            "- All prompts end with suffix ` \\n\\nLyrics:\\n`. This suffix seems very long. Consider replacing with a shorter suffix, such as `\\n\\n###\\n\\n`\n",
            "- All prompts start with prefix `Artist: `\n",
            "- All completions end with suffix `\\n###END`\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Remove 10 duplicate rows [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `tuning_88R_data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"tuning_88R_data_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` \\n\\nLyrics:\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 15.04 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys    \n",
        "path_to_module = '/content/openai_key.py'\n",
        "sys.path.append(path_to_module)\n",
        "from openai_key import key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iauIMfryh6LT",
        "outputId": "21513017-5e39-4b68-fae1-1ffd57950477"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = key"
      ],
      "metadata": {
        "id": "HmSgIpxnhL3X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"tuning_88R_data_prepared.jsonl\" -v \"tuning_88R_data_prepared.jsonl\" -m 'davinci'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHeQvVYdi-LD",
        "outputId": "9ed411b0-c4d7-441b-b029-9bd2f5a0bdcb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/310k [00:00<?, ?it/s]\rUpload progress: 100% 310k/310k [00:00<00:00, 288Mit/s]\n",
            "Uploaded file from tuning_88R_data_prepared.jsonl: file-ZY5ZlFe5EigYoVUFVTLSdLgv\n",
            "Found potentially duplicated files with name 'tuning_88R_data_prepared.jsonl', purpose 'fine-tune' and size 310199 bytes\n",
            "file-ZY5ZlFe5EigYoVUFVTLSdLgv\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 310k/310k [00:00<00:00, 390Mit/s]\n",
            "Uploaded file from tuning_88R_data_prepared.jsonl: file-CQ50YGuAfGZ5wQ8T7M63gDUl\n",
            "Created fine-tune: ft-ZSV4C5Q3wXnX7Q2heJeMTZEB\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-01-05 06:10:17] Created fine-tune: ft-ZSV4C5Q3wXnX7Q2heJeMTZEB\n",
            "[2023-01-05 06:10:58] Fine-tune costs $11.06\n",
            "[2023-01-05 06:10:58] Fine-tune enqueued. Queue number: 1\n",
            "[2023-01-05 06:11:36] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-01-05 06:12:36] Fine-tune started\n",
            "[2023-01-05 06:16:27] Completed epoch 1/4\n",
            "[2023-01-05 06:18:50] Completed epoch 2/4\n",
            "[2023-01-05 06:21:12] Completed epoch 3/4\n",
            "[2023-01-05 06:23:33] Completed epoch 4/4\n",
            "[2023-01-05 06:24:18] Uploaded model: davinci:ft-personal-2023-01-05-06-24-18\n",
            "[2023-01-05 06:24:20] Uploaded result file: file-AeKBhk2LjDAa7Ec82dlogqiz\n",
            "[2023-01-05 06:24:20] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-personal-2023-01-05-06-24-18 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_text = \"Artist: Rich Brian, Joji \\n\\nTopic: Beef \\n\\nLyrics:\\n\"\n",
        "#prompt_text = \"Artist: Rich Brian \\n\\nTopic: Hype Time \\n\\nLyrics:\\n\"\n",
        "#prompt_text = \"Artist: Joji \\n\\nTopic: Young Energy \\n\\nLyrics:\\n\"\n",
        "prompt_text = \"Artist: NIKI \\n\\nTopic: Smells Like Grass \\n\\nLyrics:\\n\"\n"
      ],
      "metadata": {
        "id": "wIf1TWLhmpLQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = key\n",
        "response = openai.Completion.create(\n",
        "  model=\"davinci:ft-personal-2023-01-05-06-24-18\",\n",
        "  prompt=prompt_text,\n",
        "  max_tokens=256,\n",
        "  temperature=0.7,\n",
        "  frequency_penalty=0.5,\n",
        "  stop=[\"\\n###END\"]\n",
        ")"
      ],
      "metadata": {
        "id": "ZWXiBY1WnLd2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_text + response['choices'][0]['text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtEw3sbPn48T",
        "outputId": "901c0dd0-4691-4474-b5b4-d7dd66443e03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artist: NIKI \n",
            "\n",
            "Topic: Smells Like Grass \n",
            "\n",
            "Lyrics:\n",
            " \n",
            "[Intro]\n",
            "Just a little bit\n",
            "Smells like grass, smells like grass\n",
            "Smells like grass, smells like grass\n",
            "[Verse ]\n",
            "I'm feeling good, I'm feeling great\n",
            "I'm looking at the stars, they're in my eyes (They're in my eyes)\n",
            "I'm feeling strange and I don't care (Yeah)\n",
            "My body is your body is my brain (Yeah)\n",
            "Does it look strange or am I blind?Do you think that I'll be fine?Will it be alright?Will it be alright?Do you think that I'll be fine?Will it be alright?Will it be alright?Yeah, yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah, whoa-oh-oh-oh-oh-oh (Yeah)\n",
            "(Oh-oh, oh-oh)\n",
            "\n",
            "[Chorus]\n",
            "It smells like grass on the meadow where we lay (We lay, we lay)\n",
            "And I don't know what to do 'cause you're not here today(You're not here today, no)I don't know why it feels so right to stay awake all night'Cause you're not here with me to see the sunrise and taste the wine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('RichBrian-Joji-Beef.txt', 'w') as writefile:\n",
        "    writefile.write(prompt_text + response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "8LktgxxBpCyI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('RichBrian-HypeTime.txt', 'w') as writefile:\n",
        "    writefile.write(prompt_text + response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "AWNLHfW0VS9A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Joji-YoungEnergy.txt', 'w') as writefile:\n",
        "    writefile.write(prompt_text + response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "c2dTGISwWG1v"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('NIKI-SmellsLikeGrass.txt', 'w') as writefile:\n",
        "    writefile.write(prompt_text + response['choices'][0]['text'])"
      ],
      "metadata": {
        "id": "m7kYSRJ7W9qX"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "baa0b97381f90d52c49ba05802debe85b0373ced8172646c844c59020a86bc33"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

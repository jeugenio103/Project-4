{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKw1vGIYfNqI",
        "outputId": "afc7375a-2b51-472f-b557-fef9351c3d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.7)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=047e30acfcdd4358bec4ce5ea0f67eeac00ce84c491cc5881ec7c4e54225f7be\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbPF7QsqfqHs",
        "outputId": "f6c97b83-70d7-4a79-f572-e89833dd32da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 281 prompt-completion pairs\n",
            "- There are 10 duplicated prompt-completion sets. These are rows: [47, 64, 165, 213, 226, 259, 266, 269, 277, 279]\n",
            "- All prompts end with suffix ` \\n\\nLyrics:\\n`. This suffix seems very long. Consider replacing with a shorter suffix, such as `\\n\\n###\\n\\n`\n",
            "- All prompts start with prefix `Artist: `\n",
            "- All completions end with suffix `\\n###END`\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Remove 10 duplicate rows [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `tuning_88R_data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"tuning_88R_data_prepared.jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` \\n\\nLyrics:\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 15.04 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f tuning_88R_data.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iauIMfryh6LT",
        "outputId": "61bbdd14-39e1-439b-df65-80dde576b1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys    \n",
        "path_to_module = '/content/openai_key.py'\n",
        "sys.path.append(path_to_module)\n",
        "from openai_key import key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HmSgIpxnhL3X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHeQvVYdi-LD",
        "outputId": "9ed411b0-c4d7-441b-b029-9bd2f5a0bdcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rUpload progress:   0% 0.00/310k [00:00<?, ?it/s]\rUpload progress: 100% 310k/310k [00:00<00:00, 288Mit/s]\n",
            "Uploaded file from tuning_88R_data_prepared.jsonl: file-ZY5ZlFe5EigYoVUFVTLSdLgv\n",
            "Found potentially duplicated files with name 'tuning_88R_data_prepared.jsonl', purpose 'fine-tune' and size 310199 bytes\n",
            "file-ZY5ZlFe5EigYoVUFVTLSdLgv\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 310k/310k [00:00<00:00, 390Mit/s]\n",
            "Uploaded file from tuning_88R_data_prepared.jsonl: file-CQ50YGuAfGZ5wQ8T7M63gDUl\n",
            "Created fine-tune: ft-ZSV4C5Q3wXnX7Q2heJeMTZEB\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-01-05 06:10:17] Created fine-tune: ft-ZSV4C5Q3wXnX7Q2heJeMTZEB\n",
            "[2023-01-05 06:10:58] Fine-tune costs $11.06\n",
            "[2023-01-05 06:10:58] Fine-tune enqueued. Queue number: 1\n",
            "[2023-01-05 06:11:36] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-01-05 06:12:36] Fine-tune started\n",
            "[2023-01-05 06:16:27] Completed epoch 1/4\n",
            "[2023-01-05 06:18:50] Completed epoch 2/4\n",
            "[2023-01-05 06:21:12] Completed epoch 3/4\n",
            "[2023-01-05 06:23:33] Completed epoch 4/4\n",
            "[2023-01-05 06:24:18] Uploaded model: davinci:ft-personal-2023-01-05-06-24-18\n",
            "[2023-01-05 06:24:20] Uploaded result file: file-AeKBhk2LjDAa7Ec82dlogqiz\n",
            "[2023-01-05 06:24:20] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-personal-2023-01-05-06-24-18 -p <YOUR_PROMPT>\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create -t \"tuning_88R_data_prepared.jsonl\" -v \"tuning_88R_data_prepared.jsonl\" -m 'davinci'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wIf1TWLhmpLQ"
      },
      "outputs": [],
      "source": [
        "prompt_text = \"Artist: Rich Brian, Joji \\n\\nTopic: Beef \\n\\nLyrics:\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZWXiBY1WnLd2"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = key\n",
        "response = openai.Completion.create(\n",
        "  model=\"davinci:ft-personal-2023-01-05-06-24-18\",\n",
        "  prompt=prompt_text,\n",
        "  max_tokens=256,\n",
        "  temperature=0.7,\n",
        "  frequency_penalty=0.5,\n",
        "  stop=[\"\\n###END\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtEw3sbPn48T",
        "outputId": "9b5c5ba3-31b0-40cc-e113-854fe9229cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artist: Rich Brian, Joji \n",
            "\n",
            "Topic: Beef \n",
            "\n",
            "Lyrics:\n",
            " \n",
            "[Chorus]\n",
            "I don't wanna beef, I just wanna see the faces of my enemies\n",
            "When this is all over, I'm only gonna take their respect\n",
            "I just wanna see their faces when they realize they've been defeated\n",
            "When this is all over, I'm only gonna take their respect (Yeah)\n",
            "I just wanna see their faces when they realize they've been defeated (Yeah)\n",
            "\n",
            "[Verse ]\n",
            "And I don't want a piece of you, no one does if you're not a threat (Yeah)\n",
            "And we'll probably never meet 'cause you're not on my level (No)\n",
            "I'ma end up on your top ten list, don't hold your breath'Cause this whole city's gettin' shook like that one time with Desiigner(Desiigner)\n",
            "Even though it's childish how y'all takin' shots at me(Shots at me)\n",
            "We all know that it's 'cause y'all don't have none of your own shit to talk about (About, about)\n",
            "Half of y'all are broke as hell and need to stop rappin' about it (About it)\n",
            "You wanna know how many shows I played without\n"
          ]
        }
      ],
      "source": [
        "print(prompt_text + response['choices'][0]['text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8LktgxxBpCyI"
      },
      "outputs": [],
      "source": [
        "with open('RichBrian-Joji-Beef.txt', 'w') as writefile:\n",
        "    writefile.write(prompt_text + response['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB8YWOOxpfiM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "baa0b97381f90d52c49ba05802debe85b0373ced8172646c844c59020a86bc33"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
